{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm thư viện\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Flatten\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy các đường dẫn đến ảnh.\n",
    "image_path = list(paths.list_images('dataset/'))\n",
    "\n",
    "# Đổi vị trí ngẫu nhiên các đường dẫn ảnh\n",
    "random.shuffle(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn ảnh sẽ là dataset/tên_loài_hoa/tên_ảnh ví dụ dataset/Bluebell/image_0241.jpg nên p.split(os.path.sep)[-2] sẽ lấy ra được tên loài hoa\n",
    "labels = [p.split(os.path.sep)[-2] for p in image_path]\n",
    "\n",
    "# Chuyển tên các loài hoa thành số\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# One-hot encoding\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ảnh và resize về đúng kích thước mà VGG 16 cần là (224,224)\n",
    "list_image = []\n",
    "for (j, imagePath) in enumerate(image_path):\n",
    "    image = load_img(imagePath, target_size=(224, 224))\n",
    "    image = img_to_array(image)\n",
    "    \n",
    "    image = np.expand_dims(image, 0)\n",
    "    image = imagenet_utils.preprocess_input(image)\n",
    "    \n",
    "    list_image.append(image)\n",
    "    \n",
    "list_image = np.vstack(list_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model VGG 16 của ImageNet dataset, include_top=False để bỏ phần Fully connected layer ở cuối.\n",
    "baseModel = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Xây thêm các layer\n",
    "# Lấy output của ConvNet trong VGG16\n",
    "fcHead = baseModel.output\n",
    "\n",
    "# Flatten trước khi dùng FCs\n",
    "fcHead = Flatten(name='flatten')(fcHead)\n",
    "\n",
    "# Thêm FC\n",
    "fcHead = Dense(256, activation='relu')(fcHead)\n",
    "fcHead = Dropout(0.5)(fcHead)\n",
    "\n",
    "# Output layer với softmax activation\n",
    "fcHead = Dense(17, activation='softmax')(fcHead)\n",
    "\n",
    "# Xây dựng model bằng việc nối ConvNet của VGG16 và fcHead\n",
    "model = model = Model(inputs=baseModel.input, outputs=fcHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia traing set, test set tỉ lệ 80-20\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_image, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation cho training data\n",
    "aug_train = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, \n",
    "                         zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "# augementation cho test\n",
    "aug_test= ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze VGG model\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "opt = RMSprop(0.001)\n",
    "model.compile(opt, 'categorical_crossentropy', ['accuracy'])\n",
    "numOfEpoch = 25\n",
    "H = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=32), \n",
    "                        steps_per_epoch=len(X_train)//32,\n",
    "                        validation_data=(aug_test.flow(X_test, y_test, batch_size=32)),\n",
    "                        validation_steps=len(X_test)//32,\n",
    "                        epochs=numOfEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze some last CNN layer:\n",
    "for layer in baseModel.layers[15:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "numOfEpoch = 35\n",
    "opt = SGD(0.001)\n",
    "model.compile(opt, 'categorical_crossentropy', ['accuracy'])\n",
    "H = model.fit_generator(aug_train.flow(X_train, y_train, batch_size=32), \n",
    "                        steps_per_epoch=len(X_train)//32,\n",
    "                        validation_data=(aug_test.flow(X_test, y_test, batch_size=32)),\n",
    "                        validation_steps=len(X_test)//32,\n",
    "                        epochs=numOfEpoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
